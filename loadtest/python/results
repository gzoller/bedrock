Python:

     scenarios: (100.00%) 1 scenario, 10000 max VUs, 1m20s max duration (incl. graceful stop):
              * default: Up to 10000 looping VUs for 50s over 3 stages (gracefulRampDown: 30s, gracefulStop: 30s)


     âœ“ status was 200

     checks.........................: 100.00% 182948 out of 182948
     data_received..................: 27 MB   527 kB/s
     data_sent......................: 16 MB   323 kB/s
     http_req_blocked...............: avg=10.67Âµs  min=0s       med=2Âµs  max=27.83ms  p(90)=4Âµs   p(95)=83Âµs
     http_req_connecting............: avg=7.05Âµs   min=0s       med=0s   max=27.82ms  p(90)=0s    p(95)=65Âµs
     http_req_duration..............: avg=1.18s    min=586Âµs    med=1.1s max=5.84s    p(90)=2.11s p(95)=2.39s
       { expected_response:true }...: avg=1.18s    min=586Âµs    med=1.1s max=5.84s    p(90)=2.11s p(95)=2.39s
     http_req_failed................: 0.00%   0 out of 182948
     http_req_receiving.............: avg=137.02Âµs min=4Âµs      med=12Âµs max=146.63ms p(90)=357Âµs p(95)=562Âµs
     http_req_sending...............: avg=7.06Âµs   min=1Âµs      med=3Âµs  max=27.79ms  p(90)=14Âµs  p(95)=24Âµs
     http_req_tls_handshaking.......: avg=0s       min=0s       med=0s   max=0s       p(90)=0s    p(95)=0s
     http_req_waiting...............: avg=1.18s    min=562Âµs    med=1.1s max=5.84s    p(90)=2.11s p(95)=2.39s
     http_reqs......................: 182948  3631.397764/s
     iteration_duration.............: avg=1.69s    min=500.69ms med=1.6s max=6.34s    p(90)=2.61s p(95)=2.89s
     iterations.....................: 182948  3631.397764/s
     vus............................: 648     min=299              max=10000
     vus_max........................: 10000   min=10000            max=10000


Bedrock:

     scenarios: (100.00%) 1 scenario, 10000 max VUs, 1m20s max duration (incl. graceful stop):
              * default: Up to 10000 looping VUs for 50s over 3 stages (gracefulRampDown: 30s, gracefulStop: 30s)


     âœ“ status was 200

     checks.........................: 100.00% 577869 out of 577869
     data_received..................: 62 MB   1.2 MB/s
     data_sent......................: 51 MB   1.0 MB/s
     http_req_blocked...............: avg=9.36Âµs   min=0s       med=2Âµs      max=148.15ms p(90)=3Âµs      p(95)=4Âµs
     http_req_connecting............: avg=6.74Âµs   min=0s       med=0s       max=148.13ms p(90)=0s       p(95)=0s
     http_req_duration..............: avg=22.9ms   min=397Âµs    med=9.24ms   max=403.65ms p(90)=63.35ms  p(95)=88.44ms
       { expected_response:true }...: avg=22.9ms   min=397Âµs    med=9.24ms   max=403.65ms p(90)=63.35ms  p(95)=88.44ms
     http_req_failed................: 0.00%   0 out of 577869
     http_req_receiving.............: avg=17.81Âµs  min=3Âµs      med=8Âµs      max=35.43ms  p(90)=19Âµs     p(95)=28Âµs
     http_req_sending...............: avg=46.94Âµs  min=1Âµs      med=5Âµs      max=31.02ms  p(90)=41Âµs     p(95)=95Âµs
     http_req_tls_handshaking.......: avg=0s       min=0s       med=0s       max=0s       p(90)=0s       p(95)=0s
     http_req_waiting...............: avg=22.84ms  min=375Âµs    med=9.18ms   max=390.4ms  p(90)=63.28ms  p(95)=88.28ms
     http_reqs......................: 577869  11446.896841/s
     iteration_duration.............: avg=523.53ms min=500.44ms med=509.94ms max=904.36ms p(90)=564.34ms p(95)=589.23ms
     iterations.....................: 577869  11446.896841/s
     vus............................: 514     min=313              max=9937
     vus_max........................: 10000   min=10000            max=10000



Analysis:

Metric                                      Python (FastAPI)     Bedrock               Difference
Total Requests Processed                    182,948              577,869               ðŸš€ Bedrock handled 3.16Ã— more requests
Avg Request Duration (http_req_duration)    1180 ms               22.90 ms             ðŸš€ Bedrock is 51.5Ã— faster
Median Latency (med http_req_duration)      1100 ms                9.24 ms             ðŸš€ Bedrock median latency is 119Ã— lower
90th Percentile (p(90) http_req_duration)   2110 ms               63.35 ms             ðŸš€ FastAPIâ€™s p(90) is 33Ã— slower
99th Percentile (p(99) http_req_duration)   2390 ms               88.44 ms             ðŸš€ FastAPIâ€™s p(99) is 27Ã— slower
Max Latency (max http_req_duration)         5840 ms              403.65 ms             ðŸš€ FastAPIâ€™s worst-case latency is 14.5Ã— worse
Requests per Second (http_reqs per sec)     3,631 req/sec        11,447 req/sec        ðŸš€ Bedrock handled 3.16Ã— more throughput


ðŸš€ ZIO HTTP is massively outperforming FastAPI under high load because:
	1.	Pythonâ€™s FastAPI cannot handle the concurrency at 10,000 RPS.
	â€¢	Avg latency jumped to 1.18s (suggesting extreme queuing delays).
	â€¢	P(99) latency is 2.39s (many requests are taking multiple seconds).
	â€¢	Peak latency is 5.84s (some requests are waiting a long time).
	â€¢	FastAPI only handled 3,631 RPS before hitting its limits.
	2.	ZIO HTTP remains extremely fast and stable under load.
	â€¢	Avg latency is only 22.9ms (near instant).
	â€¢	P(99) latency is just 88ms (vs. FastAPIâ€™s 2.39s).
	â€¢	Max latency is only 403ms (vs. FastAPIâ€™s 5.84s).
	â€¢	ZIO HTTP handled 11,447 RPS, which is 3.16Ã— the throughput of FastAPI.

Why Is FastAPI So Much Slower?

ðŸš¨ FastAPI is Likely Queuing Requests Because It Canâ€™t Handle Concurrency Efficiently
	â€¢	Pythonâ€™s GIL (Global Interpreter Lock) prevents true parallel execution.
	â€¢	FastAPIâ€™s asyncio event loop is overwhelmed, creating request backlog.
	â€¢	Requests are stacking up instead of being processed in parallel.

ðŸš¨ Why Is ZIO HTTP So Much Faster?
	â€¢	JVM is highly optimized for multithreading.
	â€¢	ZIO fibers are ultra-lightweight (can handle millions of concurrent requests).
	â€¢	ZIO HTTP has lower overhead compared to FastAPIâ€™s asyncio event loop.


